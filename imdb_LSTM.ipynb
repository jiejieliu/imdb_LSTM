{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) # max_features=20000,也就是只考虑最常见的20000个单词\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)  # 把影评的长度归一化，这里maxlen=80,如果maxlen不指定, 那么将会按照最长的那段话来计数，大于此长度的序列将被截短，小于此长度的序列将在后部填0\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 11:33:00.450722  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0728 11:33:00.493837  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0728 11:33:00.498852  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 11:33:00.830734  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0728 11:33:00.881869  5428 deprecation.py:506] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0728 11:33:01.865485  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0728 11:33:01.961742  5428 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0728 11:33:01.992823  5428 deprecation.py:323] From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/50\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.4560 - acc: 0.7834 - val_loss: 0.4084 - val_acc: 0.8175\n",
      "Epoch 2/50\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.3014 - acc: 0.8775 - val_loss: 0.3750 - val_acc: 0.8351\n",
      "Epoch 3/50\n",
      "25000/25000 [==============================] - 186s 7ms/step - loss: 0.2176 - acc: 0.9160 - val_loss: 0.4451 - val_acc: 0.8222\n",
      "Epoch 4/50\n",
      "25000/25000 [==============================] - 188s 8ms/step - loss: 0.1569 - acc: 0.9405 - val_loss: 0.4840 - val_acc: 0.8304\n",
      "Epoch 5/50\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.1087 - acc: 0.9599 - val_loss: 0.5660 - val_acc: 0.8220\n",
      "Epoch 6/50\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.0779 - acc: 0.9733 - val_loss: 0.6958 - val_acc: 0.8181\n",
      "Epoch 7/50\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.0627 - acc: 0.9792 - val_loss: 0.7683 - val_acc: 0.8052\n",
      "Epoch 8/50\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.0474 - acc: 0.9850 - val_loss: 0.7297 - val_acc: 0.8168\n",
      "Epoch 9/50\n",
      "25000/25000 [==============================] - 184s 7ms/step - loss: 0.0327 - acc: 0.9892 - val_loss: 0.8687 - val_acc: 0.8217\n",
      "Epoch 10/50\n",
      "25000/25000 [==============================] - 185s 7ms/step - loss: 0.0319 - acc: 0.9897 - val_loss: 0.9600 - val_acc: 0.8082\n",
      "Epoch 11/50\n",
      "25000/25000 [==============================] - 187s 7ms/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.9921 - val_acc: 0.8155\n",
      "Epoch 12/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 1.0227 - val_acc: 0.7999\n",
      "Epoch 13/50\n",
      "25000/25000 [==============================] - 182s 7ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 1.0161 - val_acc: 0.8132\n",
      "Epoch 14/50\n",
      "25000/25000 [==============================] - 183s 7ms/step - loss: 0.0138 - acc: 0.9956 - val_loss: 1.0037 - val_acc: 0.8102\n",
      "Epoch 15/50\n",
      "25000/25000 [==============================] - 181s 7ms/step - loss: 0.0111 - acc: 0.9968 - val_loss: 1.0488 - val_acc: 0.8126\n",
      "Epoch 16/50\n",
      "25000/25000 [==============================] - 185s 7ms/step - loss: 0.0090 - acc: 0.9968 - val_loss: 1.1453 - val_acc: 0.8080\n",
      "Epoch 17/50\n",
      "25000/25000 [==============================] - 187s 7ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 1.0968 - val_acc: 0.8089\n",
      "Epoch 18/50\n",
      "25000/25000 [==============================] - 193s 8ms/step - loss: 0.0095 - acc: 0.9966 - val_loss: 1.2571 - val_acc: 0.8096\n",
      "Epoch 19/50\n",
      "25000/25000 [==============================] - 183s 7ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 1.2314 - val_acc: 0.8111\n",
      "Epoch 20/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 1.3039 - val_acc: 0.8097\n",
      "Epoch 21/50\n",
      "25000/25000 [==============================] - 180s 7ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 1.3891 - val_acc: 0.8098\n",
      "Epoch 22/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 1.2383 - val_acc: 0.8092\n",
      "Epoch 23/50\n",
      "25000/25000 [==============================] - 181s 7ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 1.3263 - val_acc: 0.8090\n",
      "Epoch 24/50\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 1.3515 - val_acc: 0.8084\n",
      "Epoch 25/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 1.2639 - val_acc: 0.8090\n",
      "Epoch 26/50\n",
      "25000/25000 [==============================] - 180s 7ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 1.3899 - val_acc: 0.8095\n",
      "Epoch 27/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 1.3644 - val_acc: 0.8118\n",
      "Epoch 28/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.5628 - val_acc: 0.8082\n",
      "Epoch 29/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 1.4041 - val_acc: 0.8056\n",
      "Epoch 30/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 1.4522 - val_acc: 0.8083\n",
      "Epoch 31/50\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 1.4179 - val_acc: 0.8058\n",
      "Epoch 32/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 1.4808 - val_acc: 0.7954\n",
      "Epoch 33/50\n",
      "25000/25000 [==============================] - 181s 7ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 1.4261 - val_acc: 0.8045\n",
      "Epoch 34/50\n",
      "25000/25000 [==============================] - 180s 7ms/step - loss: 6.6765e-04 - acc: 0.9999 - val_loss: 1.4711 - val_acc: 0.8036\n",
      "Epoch 35/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 2.5871e-04 - acc: 1.0000 - val_loss: 1.5976 - val_acc: 0.8043\n",
      "Epoch 36/50\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 7.6711e-04 - acc: 0.9997 - val_loss: 1.5394 - val_acc: 0.8075\n",
      "Epoch 37/50\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 1.4344 - val_acc: 0.8032\n",
      "Epoch 38/50\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 1.5781 - val_acc: 0.8017\n",
      "Epoch 39/50\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 1.4739 - val_acc: 0.8021\n",
      "Epoch 40/50\n",
      "25000/25000 [==============================] - 180s 7ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.4858 - val_acc: 0.8038\n",
      "Epoch 41/50\n",
      "25000/25000 [==============================] - 185s 7ms/step - loss: 8.2319e-04 - acc: 0.9997 - val_loss: 1.4460 - val_acc: 0.8024\n",
      "Epoch 42/50\n",
      "25000/25000 [==============================] - 194s 8ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 1.4989 - val_acc: 0.8016\n",
      "Epoch 43/50\n",
      "25000/25000 [==============================] - 196s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.4500 - val_acc: 0.8010\n",
      "Epoch 44/50\n",
      "25000/25000 [==============================] - 195s 8ms/step - loss: 7.1793e-04 - acc: 0.9998 - val_loss: 1.5587 - val_acc: 0.8038\n",
      "Epoch 45/50\n",
      "25000/25000 [==============================] - 158s 6ms/step - loss: 6.4205e-04 - acc: 0.9999 - val_loss: 1.5738 - val_acc: 0.8016\n",
      "Epoch 46/50\n",
      "25000/25000 [==============================] - 108s 4ms/step - loss: 3.1035e-04 - acc: 0.9999 - val_loss: 1.6856 - val_acc: 0.8033\n",
      "Epoch 47/50\n",
      "25000/25000 [==============================] - 108s 4ms/step - loss: 7.3292e-04 - acc: 0.9998 - val_loss: 1.6440 - val_acc: 0.8028\n",
      "Epoch 48/50\n",
      "25000/25000 [==============================] - 108s 4ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 1.5134 - val_acc: 0.7983\n",
      "Epoch 49/50\n",
      "25000/25000 [==============================] - 107s 4ms/step - loss: 8.8720e-04 - acc: 0.9997 - val_loss: 1.5952 - val_acc: 0.7992\n",
      "Epoch 50/50\n",
      "25000/25000 [==============================] - 103s 4ms/step - loss: 9.8008e-04 - acc: 0.9997 - val_loss: 1.5539 - val_acc: 0.7998\n",
      "25000/25000 [==============================] - 13s 506us/step\n",
      "Test score: 1.5538521827983856\n",
      "Test accuracy: 0.7998\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))  # 将正整数下标转换为具有固定大小的向量，即用下标去寻找对应的映射 \n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
